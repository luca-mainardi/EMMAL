{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust logging level if needed\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Description:\n",
    "\n",
    "    def __init__(\n",
    "        self, attribute: str = None, value: Union[str, float, int, bool, list] = None\n",
    "    ):\n",
    "        self.description = {}\n",
    "        if attribute is not None:\n",
    "            self.description[attribute] = value\n",
    "\n",
    "    def __contains__(self, col):\n",
    "        return col in self.description\n",
    "\n",
    "    def extend(self, attribute, value):\n",
    "        self.description[attribute] = value\n",
    "        return self\n",
    "\n",
    "    def decrypt(self, translation):\n",
    "        for key, value in self.description.items():\n",
    "            if key in translation:\n",
    "                self.description[key] = translation[key][value]\n",
    "\n",
    "    def get_mask(self, df):\n",
    "        if not self.description:\n",
    "            return pd.Series([True] * len(df), index=df.index)\n",
    "        mask = pd.Series([True] * len(df), index=df.index)\n",
    "        for attribute, value in self.description.items():\n",
    "            if isinstance(value, list) and len(value) == 2:\n",
    "                # Apply range condition\n",
    "                mask &= (df[attribute] > value[0]) & (df[attribute] <= value[1])\n",
    "            else:\n",
    "                # Apply equality condition\n",
    "                mask &= df[attribute] == value\n",
    "        return mask\n",
    "\n",
    "    def __str__(self):\n",
    "        if not self.description:\n",
    "            return \"all\"\n",
    "        else:\n",
    "            result = []\n",
    "            for key, value in self.description.items():\n",
    "                if isinstance(value, list) and len(value) == 2:\n",
    "                    result.append(f\"{value[0]:.2f} < {key} ≤ {value[1]:.2f}\")\n",
    "                else:\n",
    "                    result.append(f\"{key} = {value}\")\n",
    "            return \" AND \".join(result)\n",
    "\n",
    "\n",
    "class Subgroup:\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, description: Description):\n",
    "        self.data = data\n",
    "        self.description = description\n",
    "        self.score = None\n",
    "        self.coverage = None\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, df: pd.DataFrame, description: Description):\n",
    "        mask = description.get_mask(df)\n",
    "        data = df[mask]\n",
    "        return cls(data, description)\n",
    "\n",
    "    def evaluate_quality(\n",
    "        self, overall_stats: dict, quality_measure_func, min_size, target\n",
    "    ):\n",
    "        if self.size < min_size:\n",
    "            self.score = -np.inf  # Esclude sottogruppi troppo piccoli\n",
    "        else:\n",
    "            self.score = quality_measure_func(self.data, overall_stats, target)\n",
    "\n",
    "    def decrypt_description(self, translation):\n",
    "        self.description.decrypt(translation)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def print(self):\n",
    "        logging.debug(f\"{str(self.description)} {self.score} ({self.size})\")\n",
    "\n",
    "\n",
    "class Beam:\n",
    "\n",
    "    def __init__(self, settings: dict):\n",
    "        self.subgroups = []\n",
    "        self.candidates = []\n",
    "        self.max_items = settings[\"width\"]\n",
    "        self.candidate_size = int(\n",
    "            settings.get(\"candidate_size\", settings[\"width\"] ** 2)\n",
    "        )\n",
    "        self.strategy = settings[\"strategy\"]\n",
    "        self.min_score = None\n",
    "        self.scores = []\n",
    "\n",
    "    def add(self, subgroup: Subgroup):\n",
    "        if subgroup.score == -np.inf:\n",
    "            return  # Skip subgroups with invalid scores\n",
    "\n",
    "        if len(self.candidates) < self.candidate_size:\n",
    "            self.candidates.append(subgroup)\n",
    "            self.scores.append(subgroup.score)\n",
    "            self.min_score = (\n",
    "                min(self.scores) if self.strategy == \"maximize\" else max(self.scores)\n",
    "            )\n",
    "        elif (self.strategy == \"maximize\" and subgroup.score > self.min_score) or (\n",
    "            self.strategy == \"minimize\" and subgroup.score < self.min_score\n",
    "        ):\n",
    "            idx = self.scores.index(self.min_score)\n",
    "            del self.scores[idx]\n",
    "            del self.candidates[idx]\n",
    "            self.candidates.append(subgroup)\n",
    "            self.scores.append(subgroup.score)\n",
    "            self.min_score = (\n",
    "                min(self.scores) if self.strategy == \"maximize\" else max(self.scores)\n",
    "            )\n",
    "\n",
    "    def sort(self, attribute: str = \"score\") -> None:\n",
    "        if attribute == \"score\":\n",
    "            self.candidates.sort(\n",
    "                key=lambda x: x.score, reverse=(self.strategy == \"maximize\")\n",
    "            )\n",
    "            self.subgroups.sort(\n",
    "                key=lambda x: x.score, reverse=(self.strategy == \"maximize\")\n",
    "            )\n",
    "        elif attribute == \"coverage\":\n",
    "            self.candidates.sort(\n",
    "                key=lambda x: x.score * x.coverage,\n",
    "                reverse=(self.strategy == \"maximize\"),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sort attribute\")\n",
    "\n",
    "    def select_cover_based(self):\n",
    "        self.sort()\n",
    "        if len(self.candidates) > self.max_items:\n",
    "            index = np.array([], dtype=int)\n",
    "            for subgroup in self.candidates:\n",
    "                overlap_size = np.intersect1d(subgroup.data.index.values, index).size\n",
    "                if subgroup.data.index.size == 0:\n",
    "                    subgroup.coverage = 0\n",
    "                else:\n",
    "                    subgroup.coverage = 1 - (overlap_size / subgroup.data.index.size)\n",
    "                index = np.unique(np.concatenate((index, subgroup.data.index.values)))\n",
    "            self.sort(attribute=\"coverage\")\n",
    "        self.subgroups = self.candidates[: self.max_items]\n",
    "        self.scores = [s.score for s in self.subgroups]\n",
    "        self.min_score = (\n",
    "            min(self.scores) if self.strategy == \"maximize\" else max(self.scores)\n",
    "        )\n",
    "\n",
    "    def decrypt_descriptions(self, translation):\n",
    "        for s in self.subgroups:\n",
    "            s.decrypt_description(translation)\n",
    "\n",
    "    def print(self):\n",
    "        self.sort(attribute=\"coverage\")\n",
    "        logging.debug(\"-\" * 20)\n",
    "        for s in self.subgroups:\n",
    "            s.print()\n",
    "\n",
    "\n",
    "# Quality Measures\n",
    "\n",
    "\n",
    "def mean_uncertainty_deviation(\n",
    "    subgroup_data: pd.DataFrame, overall_stats: dict, target: str\n",
    ") -> float:\n",
    "    subgroup_mean = subgroup_data[target].mean()\n",
    "    return subgroup_mean - overall_stats[\"mean\"]\n",
    "\n",
    "\n",
    "def z_score_uncertainty(\n",
    "    subgroup_data: pd.DataFrame, overall_stats: dict, target: str\n",
    ") -> float:\n",
    "    subgroup_mean = subgroup_data[target].mean()\n",
    "    subgroup_std = subgroup_data[target].std()\n",
    "    subgroup_stderr = subgroup_std / np.sqrt(len(subgroup_data))\n",
    "    if subgroup_std == 0:\n",
    "        return 0\n",
    "    return (subgroup_mean - overall_stats[\"mean\"]) / subgroup_stderr\n",
    "\n",
    "\n",
    "def calculate_entropy(values, num_bins=4):\n",
    "    counts, _ = np.histogram(values, bins=num_bins)\n",
    "    probabilities = counts / counts.sum()\n",
    "    probabilities = probabilities[probabilities > 0]  # Avoid log(0)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def wracc_uncertainty(\n",
    "    subgroup_data: pd.DataFrame, overall_stats: dict, target: str\n",
    ") -> float:\n",
    "    p = len(subgroup_data) / overall_stats[\"total_count\"]\n",
    "    subgroup_mean = subgroup_data[target].mean()\n",
    "    entropy_weight = calculate_entropy(\n",
    "        subgroup_data[target], num_bins=overall_stats[\"num_bins\"]\n",
    "    )\n",
    "    entropy_ratio = (\n",
    "        entropy_weight / overall_stats[\"entropy\"]\n",
    "        if overall_stats[\"entropy\"] != 0\n",
    "        else 1\n",
    "    )\n",
    "    return p * (subgroup_mean - overall_stats[\"mean\"]) * entropy_ratio\n",
    "\n",
    "\n",
    "def expand_description(\n",
    "    description: Description, df: pd.DataFrame, target: str, num_bins=4\n",
    "):\n",
    "    new_descriptions = []\n",
    "    used_attributes = set(description.description.keys())\n",
    "    for attribute in df.columns:\n",
    "        if attribute in used_attributes or attribute == target:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[attribute]):\n",
    "            # For numerical attributes, create bins\n",
    "            # bins = np.linspace(df[attribute].min(), df[attribute].max(), num_bins + 1)\n",
    "            bins = np.quantile(df[attribute].dropna(), np.linspace(0, 1, num_bins + 1))\n",
    "            for i in range(len(bins) - 1):\n",
    "                bin_range = [bins[i], bins[i + 1]]\n",
    "                new_desc = Description()\n",
    "                new_desc.description = description.description.copy()\n",
    "                new_desc.extend(attribute, bin_range)\n",
    "                new_descriptions.append(new_desc)\n",
    "        else:\n",
    "            # For categorical attributes, use unique values\n",
    "            unique_values = df[attribute].unique()\n",
    "            for value in unique_values:\n",
    "                new_desc = Description()\n",
    "                new_desc.description = description.description.copy()\n",
    "                new_desc.extend(attribute, value)\n",
    "                new_descriptions.append(new_desc)\n",
    "    return new_descriptions\n",
    "\n",
    "\n",
    "def beam_search(df: pd.DataFrame, settings: dict):\n",
    "\n",
    "    if \"target\" not in settings:\n",
    "        raise ValueError(\"Target attribute not specified in settings\")\n",
    "\n",
    "    target = settings[\"target\"]\n",
    "\n",
    "    # If settings have attributes key, filter the dataframe\n",
    "    if \"attributes\" in settings:\n",
    "        df = df[settings[\"attributes\"] + [target]]\n",
    "\n",
    "    overall_mean = df[target].mean()\n",
    "    overall_std = df[target].std()\n",
    "    overall_entropy = calculate_entropy(\n",
    "        df[target], num_bins=settings.get(\"num_bins\", 4)\n",
    "    )\n",
    "    overall_stats = {\n",
    "        \"mean\": overall_mean,\n",
    "        \"std\": overall_std,\n",
    "        \"entropy\": overall_entropy,\n",
    "        \"total_count\": len(df),\n",
    "        \"num_bins\": settings.get(\"num_bins\", 4),\n",
    "    }\n",
    "\n",
    "    # Select the quality measure function\n",
    "    quality_measure_name = settings.get(\"quality_measure\", \"mean_uncertainty_deviation\")\n",
    "    if quality_measure_name == \"mean_uncertainty_deviation\":\n",
    "        quality_measure_func = mean_uncertainty_deviation\n",
    "    elif quality_measure_name == \"z_score_uncertainty\":\n",
    "        quality_measure_func = z_score_uncertainty\n",
    "    elif quality_measure_name == \"wracc_uncertainty\":\n",
    "        quality_measure_func = wracc_uncertainty\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown quality measure: {quality_measure_name}\")\n",
    "\n",
    "    initial_description = Description()\n",
    "    initial_subgroup = Subgroup.create(df, initial_description)\n",
    "    initial_subgroup.evaluate_quality(\n",
    "        overall_stats, quality_measure_func, settings.get(\"min_size\", 1), target\n",
    "    )\n",
    "\n",
    "    beam = Beam(settings)\n",
    "    beam.add(initial_subgroup)\n",
    "\n",
    "    max_depth = settings.get(\"max_depth\", 3)\n",
    "    for depth in range(max_depth):\n",
    "        logging.debug(f\"Depth {depth+1}\")\n",
    "        for subgroup in beam.subgroups:\n",
    "            expanded_descriptions = expand_description(\n",
    "                subgroup.description, df, target, num_bins=settings.get(\"num_bins\", 4)\n",
    "            )\n",
    "            for description in expanded_descriptions:\n",
    "                new_subgroup = Subgroup.create(df, description)\n",
    "                new_subgroup.evaluate_quality(\n",
    "                    overall_stats,\n",
    "                    quality_measure_func,\n",
    "                    settings.get(\"min_size\", 1),\n",
    "                    target,\n",
    "                )\n",
    "                beam.add(new_subgroup)\n",
    "        beam.select_cover_based()\n",
    "\n",
    "    beam.print()\n",
    "    return beam.subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load the dataset from the CSV file\n",
    "    data = pd.read_csv(\"data/diabetes.csv\")\n",
    "\n",
    "    # Set outcome to random probability\n",
    "    data[\"Outcome\"] = data[\"Outcome\"].apply(lambda x: random.random())\n",
    "\n",
    "    # Rename outcome column\n",
    "    data = data.rename(columns={\"Outcome\": \"Probability\"})\n",
    "\n",
    "    # Calculate Uncertainty\n",
    "    data[\"Uncertainty\"] = 1 - 2 * np.abs(data[\"Probability\"] - 0.5)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>0.121426</td>\n",
       "      <td>0.242852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0.973147</td>\n",
       "      <td>0.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.608872</td>\n",
       "      <td>0.782257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0.239297</td>\n",
       "      <td>0.478595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>0.158378</td>\n",
       "      <td>0.316756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Probability  Uncertainty  \n",
       "0                     0.627   50     0.121426     0.242852  \n",
       "1                     0.351   31     0.973147     0.053706  \n",
       "2                     0.672   32     0.608872     0.782257  \n",
       "3                     0.167   21     0.239297     0.478595  \n",
       "4                     2.288   33     0.158378     0.316756  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Depth 1\n",
      "DEBUG:root:Depth 2\n",
      "DEBUG:root:Depth 3\n",
      "DEBUG:root:--------------------\n",
      "DEBUG:root:3.00 < Pregnancies ≤ 6.00 AND 62.00 < BloodPressure ≤ 72.00 3.739635202163876 (54)\n",
      "DEBUG:root:0.00 < BMI ≤ 27.30 AND 0.00 < BloodPressure ≤ 62.00 3.182958763920357 (67)\n",
      "DEBUG:root:0.24 < DiabetesPedigreeFunction ≤ 0.37 AND 3.00 < Pregnancies ≤ 6.00 3.5915818610342254 (48)\n",
      "DEBUG:root:0.24 < DiabetesPedigreeFunction ≤ 0.37 AND 117.00 < Glucose ≤ 140.25 2.3015156753916606 (47)\n",
      "DEBUG:root:29.00 < Age ≤ 41.00 AND 30.50 < Insulin ≤ 127.25 2.1611644993712966 (36)\n",
      "DEBUG:root:127.25 < Insulin ≤ 846.00 AND 24.00 < Age ≤ 29.00 1.8023910505156877 (45)\n",
      "DEBUG:root:117.00 < Glucose ≤ 140.25 AND 32.00 < BMI ≤ 36.60 1.8841491775745831 (54)\n",
      "DEBUG:root:3.00 < Pregnancies ≤ 6.00 2.1372566322027766 (175)\n",
      "DEBUG:root:0.00 < BMI ≤ 27.30 AND 99.00 < Glucose ≤ 117.00 2.0965716418514644 (54)\n",
      "DEBUG:root:3.00 < Pregnancies ≤ 6.00 AND 21.00 < Age ≤ 24.00 2.5171293062084836 (14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup 1: 3.00 < Pregnancies ≤ 6.00 AND 62.00 < BloodPressure ≤ 72.00\n",
      "  Score (z_score_uncertainty): 3.739635202163876\n",
      "  Size: 54\n",
      "\n",
      "Subgroup 2: 0.00 < BMI ≤ 27.30 AND 0.00 < BloodPressure ≤ 62.00\n",
      "  Score (z_score_uncertainty): 3.182958763920357\n",
      "  Size: 67\n",
      "\n",
      "Subgroup 3: 0.24 < DiabetesPedigreeFunction ≤ 0.37 AND 3.00 < Pregnancies ≤ 6.00\n",
      "  Score (z_score_uncertainty): 3.5915818610342254\n",
      "  Size: 48\n",
      "\n",
      "Subgroup 4: 0.24 < DiabetesPedigreeFunction ≤ 0.37 AND 117.00 < Glucose ≤ 140.25\n",
      "  Score (z_score_uncertainty): 2.3015156753916606\n",
      "  Size: 47\n",
      "\n",
      "Subgroup 5: 29.00 < Age ≤ 41.00 AND 30.50 < Insulin ≤ 127.25\n",
      "  Score (z_score_uncertainty): 2.1611644993712966\n",
      "  Size: 36\n",
      "\n",
      "Subgroup 6: 127.25 < Insulin ≤ 846.00 AND 24.00 < Age ≤ 29.00\n",
      "  Score (z_score_uncertainty): 1.8023910505156877\n",
      "  Size: 45\n",
      "\n",
      "Subgroup 7: 117.00 < Glucose ≤ 140.25 AND 32.00 < BMI ≤ 36.60\n",
      "  Score (z_score_uncertainty): 1.8841491775745831\n",
      "  Size: 54\n",
      "\n",
      "Subgroup 8: 3.00 < Pregnancies ≤ 6.00\n",
      "  Score (z_score_uncertainty): 2.1372566322027766\n",
      "  Size: 175\n",
      "\n",
      "Subgroup 9: 0.00 < BMI ≤ 27.30 AND 99.00 < Glucose ≤ 117.00\n",
      "  Score (z_score_uncertainty): 2.0965716418514644\n",
      "  Size: 54\n",
      "\n",
      "Subgroup 10: 3.00 < Pregnancies ≤ 6.00 AND 21.00 < Age ≤ 24.00\n",
      "  Score (z_score_uncertainty): 2.5171293062084836\n",
      "  Size: 14\n",
      "\n",
      "594\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"width\": 10,\n",
    "    \"candidate_size\": 100,\n",
    "    \"strategy\": \"maximize\",\n",
    "    \"max_depth\": 3,\n",
    "    \"num_bins\": 4,  # Number of bins for numerical attributes\n",
    "    \"quality_measure\": \"z_score_uncertainty\",  # Choose the quality measure here\n",
    "    # \"quality_measure\": \"wracc_uncertainty\",  # Choose the quality measure here\n",
    "    # \"quality_measure\": \"mean_uncertainty_deviation\",  # Choose the quality measure here\n",
    "    \"min_size\": 10,  # Minimum size of subgroups\n",
    "    \"target\": \"Uncertainty\",  # Target attribute for quality measure\n",
    "    \"attributes\": [\n",
    "        \"Pregnancies\",\n",
    "        \"Glucose\",\n",
    "        \"BloodPressure\",\n",
    "        \"SkinThickness\",\n",
    "        \"Insulin\",\n",
    "        \"BMI\",\n",
    "        \"DiabetesPedigreeFunction\",\n",
    "        \"Age\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "best_subgroups = beam_search(data, settings)\n",
    "\n",
    "# Print the best subgroups\n",
    "total_size = 0\n",
    "for idx, sg in enumerate(best_subgroups, 1):\n",
    "    print(f\"Subgroup {idx}: {sg.description}\")\n",
    "    print(f\"  Score ({settings['quality_measure']}): {sg.score}\")\n",
    "    print(f\"  Size: {sg.size}\")\n",
    "    total_size += sg.size\n",
    "    print()\n",
    "print(total_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
